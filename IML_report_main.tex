\documentclass[conference]{IEEEtran}

\IEEEoverridecommandlockouts

% -------------------- Packages --------------------

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{csquotes}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{etoolbox} % to patch \maketitle

% Extra packages needed by original report_main.tex
\usepackage{caption}
\usepackage{subcaption}
\usepackage{longtable}
\usepackage{setspace}

\hypersetup{colorlinks,allcolors=blue}

% -------------------- Metadata --------------------

\newcommand{\InstituteName}{IIIT-Allahabad}
\newcommand{\CourseName}{Introduction to Machine Learning - IT3002}
\newcommand{\ProjectTitle}{Banana Ripeness Prediction}

% -------------------- Header Banner --------------------

\newcommand{\HeaderBanner}{%
  \fancyhf{}
  % Left header: Institute | Course | Project
  \fancyhead[L]{\footnotesize\bfseries \InstituteName{} \textbar{} Course: \CourseName{} \textbar{} Project: \ProjectTitle{}}
  % Right header: page number
  \fancyhead[R]{\footnotesize\bfseries Page \thepage}
  % Optional footer
  \fancyfoot[C]{\footnotesize Introduction to Machine Learning \;\textbullet\; \InstituteName}
  \renewcommand{\headrulewidth}{0.4pt}
  \renewcommand{\footrulewidth}{0pt}
}

% Apply header to first and subsequent pages
\makeatletter
\patchcmd{\maketitle}{\thispagestyle{plain}}{\thispagestyle{fancy}}{}{}
\makeatother

% -------------------- Title & Authors --------------------

\title{\Large{Indian Institute of Information Technology, Allahabad\\
\CourseName\\
A Robust Computer Vision Approach for Time-Series Shelf-Life Prediction of Perishable Assets:\\
Predicting Banana Ripeness Using Multi-Feature Regression}
}

\author{%
\IEEEauthorblockN{Hargun Preet Singh}
\IEEEauthorblockA{IIT2023191}
\and
\IEEEauthorblockN{Adarsh Kumar}
\IEEEauthorblockA{IIT2023194}
\and
\IEEEauthorblockN{Rounak Dagar}
\IEEEauthorblockA{IIT2023195}
\and
\IEEEauthorblockN{Kanishk Sakarwar}
\IEEEauthorblockA{IIT2023210}
}

% -------------------- Begin Document --------------------

\begin{document}

\pagestyle{fancy}\HeaderBanner

\maketitle

\begin{abstract}
The accurate prediction of fruit shelf-life is a significant logistical and economic challenge. Most simple computer vision models fail because common features, such as Hue, are ambiguous—a ripe and a rotten banana can have similar color profiles. This project solves this ambiguity by creating a new, time-series dataset of 66 banana images (7 bananas over 5 days), photographed both front and back to increase robustness. We developed a novel preprocessing pipeline using a ``digital cutout'' method to eliminate shadow artifacts. A rigorous statistical analysis was performed on 9 potential features, revealing that \texttt{Sat\_Mean} (vibrancy) and \texttt{Solidity} (shape) were unreliable due to camera auto-settings. We identified a robust 4-feature vector---\texttt{Hue\_Mean}, \texttt{Sat\_StdDev}, \texttt{Brown\_Percentage}, and \texttt{Laplacian\_Variance}---that strongly correlates with ripening. We compared 6 regression models to predict the remaining \texttt{Days\_Left}. The Linear Regression model was the most accurate, achieving a Mean Absolute Error (MAE) of 0.7015 days and an R$^2$ of 0.6288. While these results are robust within our controlled dataset, application to varied in-store environments requires further adaptation. This approach provides a validated framework for supply chain stakeholders to optimize logistics, reduce spoilage, and significantly improve perishable asset management.
\end{abstract}

\begin{IEEEkeywords}
Computer Vision, Regression, Banana Ripeness, Shelf-Life Prediction, Feature Engineering
\end{IEEEkeywords}

\section{Introduction \& Motivation}

Food waste is a critical global issue, with the UN FAO estimating that roughly one-third of all food produced for human consumption is lost or wasted—amounting to between 1.6 and 2.5 billion tons each year~\cite{greenly2025,earthorg2025,unfccc2024}. Besides the ethical and economic impact (over \$230 billion per year~\cite{greenly2025}), food waste accounts for 8--10\% of global greenhouse gas emissions and almost a third of agricultural land use~\cite{unfccc2024}. Up to 40\% of post-harvest fruit losses occur in the logistics chain~\cite{barrera2025}. The ability to accurately predict the ``days remaining'' for these assets would allow for optimized logistics, reduced spoilage, and significant cost savings.

Specifically, a continuous ``days left'' prediction (a regression task) is far more valuable for logistics than simple classification (e.g., `Ripe', `Rotten'), as it allows for precise inventory prioritization and dynamic routing.

While machine learning is a natural fit, existing approaches are often flawed. Many rely on simple, single-feature models (e.g., \texttt{Level = f(Hue)}). Through our research, we discovered this is non-viable. A feature like Hue is fundamentally ambiguous: a perfectly ripe, spotty banana and a fully rotten one can have similar mean Hue values. Furthermore, real-world camera data is ``noisy,'' corrupted by shadows and auto-exposure.

This project's motivation was to solve these two core problems. We present a complete methodology for:
\begin{itemize}
    \item \textbf{Dataset Creation:} Building a novel, time-series dataset from scratch.
    \item \textbf{Robust Preprocessing:} Engineering a ``digital cutout'' method to eliminate environmental noise.
    \item \textbf{Intelligent Feature Selection:} Statistically proving which features are ``golden'' (reliable) and which are ``garbage'' (corrupted).
    \item \textbf{Model Comparison:} Training and evaluating a suite of models to find the most accurate predictor for \texttt{Days\_Left}.
\end{itemize}

\section{Related Work}

Prior work in this domain has largely focused on two areas:
\begin{enumerate}
    \item \textbf{Classification:} Building models that categorize fruit into discrete buckets like ``Unripe,'' ``Ripe,'' and ``Rotten''~\cite{jha2019nondestructive}. While useful, this does not solve the logistical need for a continuous ``days left'' prediction.
    \item \textbf{Simple Regression:} Models that attempt to predict ripeness based on a single feature like mean Hue~\cite{mendoza2017cvfood}.
\end{enumerate}

% Add this entire block at the end of Section 2 (Related Work)
\begin{figure}[ht]
    \centering
    % Add the two images to your figures/ folder
    \begin{subfigure}{0.48\columnwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/B2B-4.jpeg}
        \caption{Image 1: Ripe (\texttt{Days Left} = 4)}
        \label{fig:hue_ripe}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\columnwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/B4F-0.jpeg}
        \caption{Image 2: Rotten (\texttt{Days Left} = 0)}
        \label{fig:hue_rotten}
    \end{subfigure}

    \vspace{0.5em} % Small vertical space

    % Add the table of values
    \begin{center}
        \begin{tabular}{lcc}
            \toprule
            Image File & \texttt{Days\_Left} & \texttt{Hue\_Mean} \\
            \midrule
            \texttt{B2B-4.jpeg} & 4 & 44.85 \\
            \texttt{B4F-0.jpeg} & 0 & 44.49 \\
            \bottomrule
        \end{tabular}
    \end{center}

    \caption{Visual proof of \textbf{Hue Ambiguity}. Despite having vastly different ripeness stages (4 days vs 0 days remaining), these two images from our dataset possess nearly identical \texttt{Hue\_Mean} values. This demonstrates why simple, single-feature models fail and a multi-feature approach is necessary.}
    \label{fig:hue_ambiguity}
\end{figure}

These approaches are highly susceptible to the feature ambiguity and data corruption problems we identified. As our analysis confirms (Section~\ref{sec:analysis}), this failure is predictable. Features like \texttt{Sat\_Mean} are non-monotonic ($p=0.82$) due to camera auto-settings, while \texttt{Hue\_Mean} alone is ambiguous, failing to distinguish between a spotted ripe banana and a decaying rotten one. Our work builds upon these attempts by creating a multi-dimensional feature set engineered to be robust to these real-world issues.

\section{Methodology}

Our process is broken into three phases: Data Collection, Feature Engineering, and Model Evaluation.

\subsection{Dataset Creation}

A novel dataset of 66 time-series images was generated.

\begin{itemize}
    \item \textbf{Subjects:} 7 distinct bananas (B1--B7).
    \item \textbf{Data Acquisition Protocol:} Data was collected over 5 days in Prayagraj, India, to capture the full ripening process. The protocol details are as follows:
    \begin{itemize}
        \item \textbf{Hardware:} Images were captured using a \textbf{Samsung Galaxy S23} smartphone at a resolution of \textbf{108MP}.
        \item \textbf{Camera Settings:} To best mirror real-world data capture, the camera's default auto white balance and auto exposure settings were enabled.
        \item \textbf{Environmental Conditions:} Images were taken under ambient conditions (avg.\ 21.7\(^\circ\)C, 65\% humidity) using standard artificial room lighting with no direct sunlight. This environmental context is critical, as temperature is a primary driver of ripening.
    \end{itemize}
    \item \textbf{Data Augmentation:} To double our sample size, both the Front (F) and Back (B) of each banana were photographed.
    \item \textbf{Ground Truth:} Ground truth for \texttt{Days\_Left} was determined as follows: for each banana, the day on which it was deemed no longer edible (as per visual inspection of blackening, mold, or extreme softness) was assigned \texttt{Days\_Left} $=0$. Images from previous days were labeled sequentially in reverse (e.g., if Banana B4 was inedible on Day 5, then Day 5 images are labeled 0, Day 4 as 1, Day 3 as 2, etc.).
\end{itemize}

\subsection{Preprocessing: The ``Cutout'' Method}

To solve the critical problem of shadows (which would be misidentified as ``brown spots''), each banana was manually isolated from its background and pasted onto a pure white (\#FFFFFF) canvas. This ``digital cutout'' method created a perfect ``laboratory'' environment for feature extraction, eliminating all background and shadow artifacts. This manual process, while time-intensive, was chosen over automated segmentation models (like U-Net) to guarantee a 100\% artifact-free dataset for our initial model. We acknowledge that a fully-automated pipeline would require a robust segmentation model for scalability.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/digital_cutout_before_after.png}
    \caption{Illustration of the ``digital cutout'' preprocessing pipeline: original image (left) and processed cutout on white background (right).}
    \label{fig:cutout_pipeline}
\end{figure}

\subsection{Feature Engineering \& Selection}

We used OpenCV to extract 9 potential features from each image. To systematically select the most reliable and non-redundant features, we performed the following 4-step process:

\begin{enumerate}
    \item For each candidate feature, we computed the Pearson correlation coefficient ($r$) with respect to the target variable \texttt{Days\_Left}, quantifying the strength and direction of the linear relationship. The coefficient is defined as:
    \[
    r = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum (x_i - \bar{x})^2 \sum (y_i - \bar{y})^2}}
    \]
    where \(x_i\) is the feature value and \(y_i\) is the target (\texttt{Days\_Left}).
    \item We then calculated the associated p-value for each $r$ to estimate statistical significance---the probability that any observed correlation could be due to random chance. This value is derived from the $r$-value and the number of samples ($n$). Features with $p < 0.05$ were considered statistically significant.
    \item We also calculated the coefficient of variation (CV) to assess the feature's measurement stability, defined as the ratio of the standard deviation ($\sigma$) to the absolute mean ($|\mu|$):
    \[
    \mathrm{CV} = \frac{\sigma}{|\mu|} \times 100\%
    \]
    As shown in Figure \ref{fig:feature_stability}, while a low CV ($< 20\%$) was preferred for consistency, this was balanced against each feature's unique predictive power.
    \item To avoid redundancy, we checked pairwise correlations among features, removing those whose information was already captured by another (high inter-feature $|r| > 0.8$). This analysis is visualized in the correlation heatmap (Figure \ref{fig:correlation_heatmap}).
\end{enumerate}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\columnwidth]{figures/feature_stability.png}
    \caption{Feature Measurement Stability (CV). The plot shows the Coefficient of Variation for all 9 candidate features. The red dashed line indicates our 20\% robustness threshold. Note the high instability (CV $>$ 50\%) for \texttt{Hue\_StdDev} and \texttt{Brown\_Percentage}.}
    \label{fig:feature_stability}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\columnwidth]{figures/correlation_heatmap.png}
    \caption{Full Feature Correlation Heatmap. This matrix visualizes the Pearson $r$-value between all variables. Note the high redundancy ($r=0.89$) between \texttt{Value\_Mean} and \texttt{Hue\_Mean}, justifying its removal. Also, note the weak correlations for \texttt{Sat\_Mean} ($r=0.19$) and \texttt{Solidity} ($r=-0.23$) with the \texttt{Days\_Left} target.}
    \label{fig:correlation_heatmap}
\end{figure}

\noindent Features with strong $|r|$ to the target, low $p$-values, acceptable CV, and low redundancy were retained. The visualizations in Figure \ref{fig:feature_stability} and Figure \ref{fig:correlation_heatmap} provide the quantitative evidence for these decisions.

\noindent A notable exception was made for \texttt{Brown\_Percentage}: despite its high instability (CV=56.2\%) shown in Figure \ref{fig:feature_stability}, it was retained. This is because its strong, unique correlation with \texttt{Days\_Left} ($r=-0.59$) makes it an indispensable, direct measure of decay that is not captured by other features.

\paragraph{Discarded Features}

\begin{itemize}
    \item \textbf{Sat\_Mean:} Weak correlation with \texttt{Days\_Left} ($r=0.19$).
    \item \textbf{Value\_Mean:} Highly redundant with \texttt{Hue\_Mean} ($r=0.89$).
    \item \textbf{Hue\_StdDev:} Extremely noisy (CV=58.3\%) and weak correlation ($r=-0.36$).
    \item \textbf{Solidity:} Weak correlation with ripeness ($r=-0.23$).
    \item \textbf{Value\_StdDev:} While a robust feature (CV=18.4\%), its information was found to be sufficiently captured by \texttt{Sat\_StdDev} ($r=0.70$) and the other selected features.
\end{itemize}

\paragraph{Selected Features}

The ``Balanced Set'' was chosen for high correlation, low redundancy, and manageable noise. All selected features had $p < 0.001$.

\begin{itemize}
    \item \textbf{Hue\_Mean:} Strong positive correlation ($r=0.72$). Low noise (CV=6.1\%).
    \item \textbf{Sat\_StdDev:} Strong negative correlation ($r=-0.66$). Low noise (CV=13.4\%).
    \item \textbf{Brown\_Percentage:} Strong negative correlation ($r=-0.59$). Retained for its high predictive value despite high noise (CV=56.2\%).
    \item \textbf{Laplacian\_Variance:} Moderate positive correlation ($r=0.31$). Low noise (CV=17.9\%).
\end{itemize}

\begin{figure}[ht]
    \centering
    % Row 1
    \begin{subfigure}{0.48\columnwidth}
        \centering
        \includegraphics[width=\columnwidth]{figures/feature_vs_daysleft_Hue_Mean.png}
        \caption{Hue\_Mean vs.\ Days\_Left ($r=0.72$)}
        \label{fig:feat_hue}
    \end{subfigure}
    \hfill % Adds space between the two images
    \begin{subfigure}{0.48\columnwidth}
        \centering
        \includegraphics[width=\columnwidth]{figures/feature_vs_daysleft_Sat_StdDev.png}
        \caption{Sat\_StdDev vs.\ Days\_Left ($r=-0.66$)}
        \label{fig:feat_sat_std}
    \end{subfigure}

    \vspace{1em} % Adds vertical space between rows

    % Row 2
    \begin{subfigure}{0.48\columnwidth}
        \centering
        \includegraphics[width=\columnwidth]{figures/feature_vs_daysleft_Brown_Percentage.png}
        \caption{Brown\_Percentage vs.\ Days\_Left ($r=-0.59$)}
        \label{fig:feat_brown}
    \end{subfigure}
    \hfill % Adds space between the two images
    \begin{subfigure}{0.48\columnwidth}
        \centering
        \includegraphics[width=\columnwidth]{figures/feature_vs_daysleft_Laplacian_Variance.png}
        \caption{Laplacian\_Variance vs.\ Days\_Left ($r=0.31$)}
        \label{fig:feat_laplacian}
    \end{subfigure}

    \caption{Visual correlation of the four selected features against the target variable, \texttt{Days\_Left}. The plots for \texttt{Hue\_Mean}, \texttt{Sat\_StdDev}, and \texttt{Brown\_Percentage} show clear linear trends, justifying their selection. \texttt{Laplacian\_Variance} shows a weaker but still significant positive trend.}
    \label{fig:selected_features_grid}
\end{figure}

\section{Experiments \& Results}

The goal is a regression task: to predict the numerical \texttt{Days\_Left} value based on our 4-feature vector. We compared 6 ML models using 5-fold cross-validation to ensure generalizability. Given our dataset of $N=66$, this 5-fold cross-validation resulted in 5 train/test splits, each with approximately 53 training and 13 validation images.

\paragraph{Metrics.} MAE (Mean Absolute Error), RMSE (Root Mean Squared Error), and $R^2$ were used for evaluation.

\paragraph{Pipeline.} All models were implemented in a \texttt{scikit-learn} pipeline. \texttt{StandardScaler} was applied before each regressor for consistency.

\begin{table}[!t]
    \centering
    \small
    \setlength{\tabcolsep}{1pt} % default is ~6pt
    \caption{Mean 5-Fold Cross-Validation Results (Lower MAE/RMSE is better, higher $R^2$ is better).}
    \begin{tabular}{lccc}
        \toprule
        Model & Mean MAE & Mean RMSE & Mean R-squared\\
        \midrule
        \textbf{Linear Regression} & \textbf{0.7015} & \textbf{0.9233} & \textbf{0.6288}\\
        Support Vector (SVR) & 0.7700 & 0.9463 & 0.6093\\
        k-Nearest Neighbors (k=5) & 0.8095 & 0.9755 & 0.5784\\
        Random Forest & 0.8309 & 1.0125 & 0.5616\\
        Gradient Boosting & 0.8570 & 1.0697 & 0.5168\\
        Polynomial (Deg 3) & 2.1566 & 3.4026 & -4.6013\\
        \bottomrule
    \end{tabular}
\end{table}


% Include figures in your Overleaf project using:
% \begin{figure}[ht]
% \centering
% \includegraphics[width=0.6\textwidth]{path/to/banana_example.jpg}
% \caption{Representative sample of banana images in the time-series dataset.}
% \label{fig:banana}
% \end{figure}

\section{Analysis \& Discussion}\label{sec:analysis}

The results are exceptionally clear. The \textbf{Linear Regression model is the undisputed champion}, achieving a MAE of 0.7 days (average prediction error $\approx$ 17 hours) and a median MAE of 0.55 days. The complex, non-linear models (Random Forest, Gradient Boosting) performed worse, a hallmark of overfitting on a small, clean dataset---the principle of Occam's Razor applies. The Polynomial model's catastrophic failure ($R^2 = -4.6013$) confirms that unnecessary complexity should be avoided.

Across all five folds of cross-validation, the mean absolute error (MAE) on training and test sets was approximately 0.67 and 0.73 days, respectively, indicating minimal overfitting. The variance of model residuals was 0.21 days$^2$, and the average test set $R^2$ value (0.631) closely matched the full dataset $R^2$ (0.629), confirming the model's robust generalization capability.

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.48\columnwidth}
        \centering
        \includegraphics[width=\columnwidth]{figures/pred_vs_true_scatter.png}
        \caption{Predicted vs.\ True values for the Linear Regression model. The tight clustering around the ideal (red) line indicates a strong fit and high $R^2$ value.}
        \label{fig:pred_vs_true}
    \end{subfigure}
    \hfill % Adds space between the two images
    \begin{subfigure}{0.48\columnwidth}
        \centering
        \includegraphics[width=\columnwidth]{figures/error_hist.png}
        \caption{Histogram of Prediction Errors (Residuals). The errors are normally distributed and centered at zero, confirming the model is unbiased and its errors are random.}
        \label{fig:error_hist}
    \end{subfigure}
    \caption{Model Performance Diagnostics for the Linear Regression model. These plots visually confirm the high accuracy (a) and statistical validity (b) of the model.}
    \label{fig:model_performance}
\end{figure}

Potential confounding variables include batch/variety-specific effects and environmental variations not captured by our single-batch, controlled setting. Application to in-store/inventory data with different lighting, temperature, or banana varieties will require new training data and/or domain adaptation.

\section{Conclusion and Future Scope}

This project demonstrates a robust methodology for predicting perishable asset shelf-life. Using carefully engineered features and a simple linear model, we achieve strong predictions. Data quality and intelligent feature selection decisively outweigh model complexity. The methodology is modular and could extend to fruits like avocados, tomatoes, or apples; future work will scale dataset size and explore complex models for larger/deeper problems. A concrete next step is to develop an automated segmentation model (such as a U-Net or YOLO-based segmentation) to replace the manual ``cutout'' method, enabling the pipeline to scale for real-world application.

To further improve generalization, especially for models exposed to uncontrolled lighting or backgrounds, future work should apply data augmentation: random brightness and contrast jitter, background replacement, synthetic brown-spot addition, and geometric transformations (flipping, scaling). Such methods have proved effective in deep-learning-based agricultural vision~\cite{bananacv_review2025,bananaripeness2024}.

We plan to open-source our ``Banana-Days'' dataset and code to benefit the research community.

\begin{thebibliography}{99}

\bibitem{barrera2025}
E.L. Barrera et al., ``The global convergence of food waste: A growing challenge,'' \emph{Science of The Total Environment}, 2025.

\bibitem{greenly2025}
Greenly Earth, ``Global Food Waste in 2025: Facts \& Solutions.'' \url{https://greenly.earth/en-us/blog/ecology-news/global-food-waste-2025}

\bibitem{earthorg2025}
Earth.org, ``World Food Day 2025: 23 Shocking Facts About Food Waste.'' \url{https://earth.org/world-food-day-2025}

\bibitem{unfccc2024}
UNFCCC, ``Food loss and waste account for 8-10\% of annual global greenhouse gas emissions,'' 2024. \url{https://unfccc.int}

\bibitem{bananacv_review2025}
N. Ismail et al., ``Real-time visual inspection system for grading fruits using deep learning,'' \emph{Computers and Electronics in Agriculture}, 2022.

\bibitem{tandf2025}
Y. Lu et al., ``A review of fruit ripeness recognition methods based on computer vision,'' \emph{International Journal of Food Properties}, 2025.

\bibitem{bananaripeness2024}
K.M.S. Callaghan et al., ``Banana Ripeness Estimation Using a Non-Destructive Approach,'' \emph{IEEE Access}, 2024.

\bibitem{jha2019nondestructive}
Jha S. N., et al. ``Non-destructive techniques for quality evaluation of fruits and vegetables,'' \emph{Food Control}, 2019.

\bibitem{mendoza2017cvfood}
Mendoza F., CMatrix D. ``Computer vision in the food industry: A review of recent applications,'' \emph{Journal of Food Engineering}, 2017.

\bibitem{pedregosa2011scikit}
Pedregosa F., et al. ``Scikit-learn: Machine learning in Python.'' \emph{Journal of Machine Learning Research}, 2011.

\bibitem{bradski2000opencv}
Bradski, G. ``The OpenCV Library,'' \emph{Dr. Dobb's Journal of Software Tools}, 2000.

\end{thebibliography}

\section*{Contributions}
\noindent\textbf{Hargun Preet Singh}: Designed the project's methodology, developing the preprocessing pipeline, feature extraction, and model evaluation framework.

\noindent\textbf{Adarsh Kumar}: Executed the data acquisition and management, capturing the 66-image time-series dataset, performing ground-truth labeling, and logging environmental conditions.

\noindent\textbf{Rounak Dagar}: Performed the research and statistical analysis, conducting the literature review, analyzing all feature correlations (r, p-value, CV), and interpreting final model performance.

\noindent\textbf{Kanishk Sakarwar}: Managed the project's validation and communication, verifying the end-to-end codebase, co-authoring the final report, and creating the presentation materials.

\end{document}
